{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python3\n",
    "\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as matdates\n",
    "from matplotlib2tikz import save as tikz_save\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import locale\n",
    "import statistics\n",
    "from scipy.stats.mstats import gmean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['run-comerge-2019_07_20__11_51_50-run-1.log', 'run-comerge-2019_07_20__11_51_50-run-2.log', 'run-comerge-2019_07_20__11_51_50-run-3.log', 'run-comerge-2019_07_20__11_51_50-run-4.log', 'run-comerge-2019_07_20__11_51_50-run-5.log']\n"
     ]
    }
   ],
   "source": [
    "comerge_run_list = [log for log in os.listdir('.') if 'run-comerge' in log and log.endswith('.log')]\n",
    "print(comerge_run_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['./comerge-pb-results-2019_07_20__11_51_50', './comerge-pb-results-2019_07_20__14_31_07', './comerge-pb-results-2019_07_20__17_10_53', './comerge-pb-results-2019_07_20__19_51_06', './comerge-pb-results-2019_07_20__22_33_51']\n"
     ]
    }
   ],
   "source": [
    "results_dirs = []\n",
    "for log in comerge_run_list:\n",
    "    with open(log, 'rt') as fd:\n",
    "        line = fd.readline().strip().split(' ')\n",
    "        results_dirs.append(line[1])\n",
    "print(results_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'comerge-pb-results-2019_07_20__11_51_50': ['pb-dram0-intelsdp1044-2019_07_20__11_51_50.log', 'pb-dram1-intelsdp1044-2019_07_20__11_51_50.log', 'pb-make-intelsdp1044-2019_07_20__11_51_50.log', 'pb-pmem1-intelsdp1044-2019_07_20__11_51_50.log', 'pb-pmem7-intelsdp1044-2019_07_20__11_51_50.log'], 'comerge-pb-results-2019_07_20__14_31_07': ['pb-dram0-intelsdp1044-2019_07_20__14_31_07.log', 'pb-dram1-intelsdp1044-2019_07_20__14_31_07.log', 'pb-make-intelsdp1044-2019_07_20__14_31_07.log', 'pb-pmem1-intelsdp1044-2019_07_20__14_31_07.log', 'pb-pmem7-intelsdp1044-2019_07_20__14_31_07.log'], 'comerge-pb-results-2019_07_20__17_10_53': ['pb-dram0-intelsdp1044-2019_07_20__17_10_53.log', 'pb-dram1-intelsdp1044-2019_07_20__17_10_53.log', 'pb-make-intelsdp1044-2019_07_20__17_10_53.log', 'pb-pmem1-intelsdp1044-2019_07_20__17_10_53.log', 'pb-pmem7-intelsdp1044-2019_07_20__17_10_53.log'], 'comerge-pb-results-2019_07_20__19_51_06': ['pb-dram0-intelsdp1044-2019_07_20__19_51_06.log', 'pb-dram1-intelsdp1044-2019_07_20__19_51_06.log', 'pb-make-intelsdp1044-2019_07_20__19_51_06.log', 'pb-pmem1-intelsdp1044-2019_07_20__19_51_06.log', 'pb-pmem7-intelsdp1044-2019_07_20__19_51_06.log'], 'comerge-pb-results-2019_07_20__22_33_51': ['pb-dram0-intelsdp1044-2019_07_20__22_33_51.log', 'pb-dram1-intelsdp1044-2019_07_20__22_33_51.log', 'pb-make-intelsdp1044-2019_07_20__22_33_51.log', 'pb-pmem1-intelsdp1044-2019_07_20__22_33_51.log', 'pb-pmem7-intelsdp1044-2019_07_20__22_33_51.log']}\n"
     ]
    }
   ],
   "source": [
    "data = { x[2:] : os.listdir(x) for x in results_dirs}\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_key(logname):\n",
    "    \"\"\"Given a log file name, figure out what kind of memory was being used and return the correct key\"\"\"\n",
    "    if 'dram0' in logname: return 'dram0'\n",
    "    if 'dram1' in logname: return 'dram1'\n",
    "    if 'pmem1' in logname: return 'pmem1'\n",
    "    if 'pmem7' in logname: return 'pmem7'\n",
    "    if 'make' in logname: return 'make'\n",
    "    raise ValueException"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerfDataTypes:\n",
    "    \"\"\"\n",
    "             11,266.70 msec task-clock                #    1.000 CPUs utilized\n",
    "                     4      context-switches          #    0.355 M/sec\n",
    "                     0      cpu-migrations            #    0.000 K/sec\n",
    "                22,030      page-faults               # 1955.441 M/sec\n",
    "        41,292,991,932      cycles                    # 3665275.336 GHz                   (30.75%)\n",
    "        57,539,842,386      instructions              #    1.39  insn per cycle           (38.44%)\n",
    "         6,774,876,761      branches                  # 601356005.770 M/sec               (38.45%)\n",
    "             4,832,518      branch-misses             #    0.07% of all branches          (38.46%)\n",
    "        13,526,507,060      L1-dcache-loads           # 1200648594.000 M/sec              (38.47%)\n",
    "         9,012,615,601      L1-dcache-load-misses     #   66.63% of all L1-dcache hits    (38.47%)\n",
    "           849,715,461      LLC-loads                 # 75422994.941 M/sec                (30.78%)\n",
    "             4,911,229      LLC-load-misses           #    0.58% of all LL-cache hits     (30.78%)\n",
    "       <not supported>      L1-icache-loads\n",
    "             3,776,205      L1-icache-load-misses                                         (30.78%)\n",
    "        13,547,867,184      dTLB-loads                # 1202544575.182 M/sec              (30.78%)\n",
    "         2,066,428,912      dTLB-load-misses          #   15.25% of all dTLB cache hits   (30.77%)\n",
    "                   338      iTLB-loads                #   30.002 M/sec                    (30.76%)\n",
    "                 5,183      iTLB-load-misses          # 1533.43% of all iTLB cache hits   (30.75%)\n",
    "       <not supported>      L1-dcache-prefetches\n",
    "       <not supported>      L1-dcache-prefetch-misses\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod \n",
    "    def convert_float(value):\n",
    "        \"\"\"Convert a string float value\"\"\"\n",
    "        locale.setlocale(locale.LC_NUMERIC, '') #default locale\n",
    "        return locale.atof(value)\n",
    "    \n",
    "    @staticmethod\n",
    "    def convert_int(value):\n",
    "        \"\"\"Convert a string int value\"\"\"\n",
    "        locale.setlocale(locale.LC_NUMERIC, '') # default\n",
    "        return locale.atoi(value)\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def task_clock(line):\n",
    "        \"\"\"             11,266.70 msec task-clock                #    1.000 CPUs utilized\"\"\"\n",
    "        if line is None: line = \"             11,266.70 msec task-clock                #    1.000 CPUs utilized\" # Testing\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [11,266.70, 'msec', 'task-clock']\n",
    "        field2 = fields[1].split() # [1.000, 'CPUs' 'utilized']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_float(field1[0]), \n",
    "                              field1[1], \n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              \" \".join(field2[1:]))}\n",
    "\n",
    "    @staticmethod\n",
    "    def context_switches(line):\n",
    "        \"\"\"                     4      context-switches          #    0.355 M/sec\"\"\"\n",
    "        if line is None: line = \"                     4      context-switches          #    0.355 M/sec\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [4, 'context-switches']\n",
    "        field2 = fields[1].split() # ['0.355', 'M/sec']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def cpu_migrations(line):\n",
    "        \"\"\"0      cpu-migrations            #    0.000 K/sec\"\"\"\n",
    "        if line is None: line = \"0      cpu-migrations            #    0.000 K/sec\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # ['0', 'cpu-migrations']\n",
    "        field2 = fields[1].split() # ['0.000', 'K/sec']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def page_faults(line):\n",
    "        \"\"\"                22,030      page-faults               # 1955.441 M/sec    \"\"\"\n",
    "        if line is None:  line = \"                22,030      page-faults               # 1955.441 M/sec    \"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # ['22,030', 'page-faults']\n",
    "        field2 = fields[1].split() # ['1955.441', 'M/sec']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1])}\n",
    "\n",
    "    @staticmethod\n",
    "    def cycles(line):\n",
    "        \"\"\"        41,292,991,932      cycles                    # 3665275.336 GHz                   (30.75%)\"\"\"\n",
    "        if line is None: line = \"        41,292,991,932      cycles                    # 3665275.336 GHz                   (30.75%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [41,292,991,932, 'cycles']\n",
    "        field2 = fields[1].split() # ['3.665275', 'GHz', '(30.75%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1],\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def instructions(line):\n",
    "        \"\"\"        57,539,842,386      instructions              #    1.39  insn per cycle           (38.44%)\"\"\"\n",
    "        if line is None: line = \"        57,539,842,386      instructions              #    1.39  insn per cycle           (38.44%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [57,539,842,386, 'instructions']\n",
    "        field2 = fields[1].split() # [1.39, 'insn', 'per', 'cycle', '(38.44%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              \" \".join(field2[1:3]),\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def branches(line):\n",
    "        \"\"\"         6,774,876,761      branches                  # 601356005.770 M/sec               (38.45%)\"\"\"\n",
    "        if line is None: line = \"         6,774,876,761      branches                  # 601356005.770 M/sec               (38.45%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [6,774,876,761, 'branches']\n",
    "        field2 = fields[1].split() # ['601356005.770', 'M/sec', '(38.45%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1],\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def branch_misses(line):\n",
    "        \"\"\"             4,832,518      branch-misses             #    0.07% of all branches          (38.46%)\"\"\"\n",
    "        if line is None: line = \"             4,832,518      branch-misses             #    0.07% of all branches          (38.46%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [4,832,518, 'branch-misses']\n",
    "        field2 = fields[1].split() # [0.07%, 'of', 'all', 'branches', '(38.46%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              \" \".join(field2[1:4]),\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_dcache_loads(line):\n",
    "        \"\"\"        13,526,507,060      L1-dcache-loads           # 1200648594.000 M/sec              (38.47%)        \"\"\"\n",
    "        if line is None: line = \"        13,526,507,060      L1-dcache-loads           # 1200648594.000 M/sec              (38.47%)        \"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [13,526,507,060, 'L1-dcache-loads']\n",
    "        field2 = fields[1].split() # ['1200648594.000', 'M/sec', '(38.47%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1],\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_dcache_load_misses(line):\n",
    "        \"\"\"         9,012,615,601      L1-dcache-load-misses     #   66.63% of all L1-dcache hits    (38.47%)        \"\"\"\n",
    "        if line is None: line =  \"         9,012,615,601      L1-dcache-load-misses     #   66.63% of all L1-dcache hits    (38.47%)        \"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [9,012,615,601, 'L1-dcache-load-misses']\n",
    "        field2 = fields[1].split() # [66.63%, 'of', 'all', 'L1-dcache', 'hits', (38.46%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              \" \".join(field2[1:5]),\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def llc_loads(line):\n",
    "        \"\"\"           849,715,461      LLC-loads                 # 75422994.941 M/sec                (30.78%)\"\"\"\n",
    "        if line is None: line = \"           849,715,461      LLC-loads                 # 75422994.941 M/sec                (30.78%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [849,715,461, 'LC-loads']\n",
    "        field2 = fields[1].split() # ['75422994.941', 'M/sec', '(30.78%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1],\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def llc_load_misses(line):\n",
    "        \"\"\"             4,911,229      LLC-load-misses           #    0.58% of all LL-cache hits     (30.78%)\"\"\"\n",
    "        if line is None: line = \"             4,911,229      LLC-load-misses           #    0.58% of all LL-cache hits     (30.78%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [4,911,229, 'LLC-load-misses']\n",
    "        field2 = fields[1].split() # [0.58%, 'of', 'all', 'LL-cache', 'hits', (30.78%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              \" \".join(field2[1:5]),\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_icache_loads(line):\n",
    "        \"\"\"       <not supported>      L1-icache-loads\"\"\"\n",
    "        if line is None: line = \"       <not supported>      L1-icache-loads\"\n",
    "        if 'not supported' in line: return None\n",
    "        print(line)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_icache_load_misses(line):\n",
    "        \"\"\"             3,776,205      L1-icache-load-misses                                         (30.78%)\"\"\"\n",
    "        if line is None: line = \"             3,776,205      L1-icache-load-misses                                         (30.78%)\"\n",
    "        fields = line.strip().split() # ['3,776,205', 'L1-icache-load-misses', '(30.78%)']\n",
    "        return {fields[1] : (PerfDataTypes.convert_int(fields[0]), \n",
    "                             PerfDataTypes.convert_float(fields[-1][fields[-1].index('(')+1:fields[-1].index('%')]))}\n",
    "\n",
    "    @staticmethod\n",
    "    def dtlb_loads(line):\n",
    "        \"\"\"        13,547,867,184      dTLB-loads                # 1202544575.182 M/sec              (30.78%)\"\"\"\n",
    "        if line is None: line = \"        13,547,867,184      dTLB-loads                # 1202544575.182 M/sec              (30.78%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [13,547,867,184, 'dTLB-loads']\n",
    "        field2 = fields[1].split() # ['601356005.770', 'M/sec', '(38.45%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1],\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def dtlb_load_misses(line):\n",
    "        \"\"\"         2,066,428,912      dTLB-load-misses          #   15.25% of all dTLB cache hits   (30.77%)\"\"\"\n",
    "        if line is None: line = \"         2,066,428,912      dTLB-load-misses          #   15.25% of all dTLB cache hits   (30.77%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [2,066,428,912, 'dTLB-load-misses']\n",
    "        field2 = fields[1].split() # ['15.25%', 'of', 'all', 'dTLB', 'cache', 'hits', '(30.77%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0][:field2[0].index('%')]),\n",
    "                              \" \".join(field2[1:6]),\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def itlb_loads(line):\n",
    "        \"\"\"                   338      iTLB-loads                #   30.002 M/sec                    (30.76%)\"\"\"\n",
    "        if line is None: line = \"                   338      iTLB-loads                #   30.002 M/sec                    (30.76%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [338, 'iTLB-loads']\n",
    "        field2 = fields[1].split() # ['30.002', 'M/sec', '(30.76%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0]),\n",
    "                              field2[1],\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def itlb_load_misses(line):\n",
    "        \"\"\"                 5,183      iTLB-load-misses          # 1533.43% of all iTLB cache hits   (30.75%)\"\"\"\n",
    "        if line is None: line = \"                 5,183      iTLB-load-misses          # 1533.43% of all iTLB cache hits   (30.75%)\"\n",
    "        fields = line.strip().split('#')\n",
    "        field1 = fields[0].split() # [5,183, 'iTLB-load-misses']\n",
    "        field2 = fields[1].split() # ['1533.43%', 'of', 'all', 'iTLB', 'cache', 'hits', '(30.75%)']\n",
    "        return {field1[-1] : (PerfDataTypes.convert_int(field1[0]),\n",
    "                              PerfDataTypes.convert_float(field2[0][:field2[0].index('%')]),\n",
    "                              \" \".join(field2[1:6]),\n",
    "                              PerfDataTypes.convert_float(field2[-1][field2[-1].index('(')+1:field2[-1].index('%')])) }\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_dcache_prefetches(line):\n",
    "        \"\"\"       <not supported>      L1-dcache-prefetches\"\"\"\n",
    "        if line is None: line = \"       <not supported>      L1-dcache-prefetches\"\n",
    "        if 'not supported' in line: return None\n",
    "        print(line)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def l1_dcache_prefetch_misses(line):\n",
    "        \"\"\"       <not supported>      L1-dcache-prefetch-misses\"\"\"\n",
    "        if line is None: line = \"       <not supported>      L1-dcache-prefetch-misses\"\n",
    "        if 'not supported' in line: return None\n",
    "        print(line)\n",
    "        raise NotImplementedError\n",
    "\n",
    "    @staticmethod\n",
    "    def test():\n",
    "        results = []\n",
    "        results.append(PerfDataTypes.branch_misses(None))\n",
    "        results.append(PerfDataTypes.branches(None))\n",
    "        results.append(PerfDataTypes.context_switches(None))\n",
    "        results.append(PerfDataTypes.cpu_migrations(None))\n",
    "        results.append(PerfDataTypes.cycles(None))\n",
    "        results.append(PerfDataTypes.dtlb_load_misses(None))\n",
    "        results.append(PerfDataTypes.dtlb_loads(None))\n",
    "        results.append(PerfDataTypes.instructions(None))\n",
    "        results.append(PerfDataTypes.itlb_load_misses(None))\n",
    "        results.append(PerfDataTypes.itlb_loads(None))\n",
    "        results.append(PerfDataTypes.l1_dcache_load_misses(None))\n",
    "        results.append(PerfDataTypes.l1_dcache_loads(None))\n",
    "        results.append(PerfDataTypes.l1_dcache_prefetch_misses(None))\n",
    "        results.append(PerfDataTypes.l1_dcache_prefetches(None))\n",
    "        results.append(PerfDataTypes.l1_icache_load_misses(None))\n",
    "        results.append(PerfDataTypes.l1_icache_loads(None))\n",
    "        results.append(PerfDataTypes.llc_load_misses(None))\n",
    "        results.append(PerfDataTypes.llc_loads(None))\n",
    "        results.append(PerfDataTypes.page_faults(None))\n",
    "        results.append(PerfDataTypes.task_clock(None))\n",
    "        return results\n",
    "\n",
    "class PerfData:\n",
    "    \n",
    "    counters = (('task-clock', PerfDataTypes.task_clock),\n",
    "            ('context-switches', PerfDataTypes.context_switches),\n",
    "            ('cpu-migrations', PerfDataTypes.cpu_migrations),\n",
    "            ('page-faults', PerfDataTypes.page_faults),\n",
    "            ('cycles', PerfDataTypes.cycles),\n",
    "            ('instructions', PerfDataTypes.instructions),\n",
    "            ('branches', PerfDataTypes.branches),\n",
    "            ('branch-misses', PerfDataTypes.branch_misses), \n",
    "            ('L1-dcache-loads', PerfDataTypes.l1_dcache_loads),\n",
    "            ('L1-dcache-load-misses', PerfDataTypes.l1_dcache_load_misses),\n",
    "            ('LLC-loads', PerfDataTypes.llc_loads),\n",
    "            ('LLC-load-misses', PerfDataTypes.llc_load_misses),\n",
    "            ('L1-icache-loads', PerfDataTypes.l1_icache_loads),\n",
    "            ('L1-icache-load-misses', PerfDataTypes.l1_icache_load_misses),\n",
    "            ('dTLB-loads', PerfDataTypes.dtlb_loads),\n",
    "            ('dTLB-load-misses', PerfDataTypes.dtlb_load_misses),\n",
    "            ('iTLB-loads', PerfDataTypes.itlb_loads),\n",
    "            ('iTLB-load-misses', PerfDataTypes.itlb_load_misses),\n",
    "            ('L1-dcache-prefetches', PerfDataTypes.l1_dcache_prefetches),\n",
    "            ('L1-dcache-prefetch-misses', PerfDataTypes.l1_dcache_prefetch_misses))\n",
    "\n",
    "    def __init__(self, lines):\n",
    "        self.times = {}\n",
    "        self.stats = {}\n",
    "        index = 0\n",
    "        while index < len(lines):\n",
    "            if len(lines[index]) < 10: # short lines are usually empty\n",
    "                index = index + 1\n",
    "                continue\n",
    "            if 'not supported' in lines[index]: # means that the CPU doesn't support whatever this was - skip\n",
    "                index = index + 1\n",
    "                continue\n",
    "            if 'elapsed' in lines[index]: break\n",
    "            for ctr, ctr_func in self.counters:\n",
    "                hash_index = lines[index].find('#')\n",
    "                if ctr in lines[index][0:hash_index]:\n",
    "                    assert ctr not in self.stats, 'Duplicate perf type {}'.format(ctr)\n",
    "                    self.stats[ctr] = ctr_func(lines[index])\n",
    "                    break\n",
    "            index = index + 1\n",
    "        # at this point we should have the execution times\n",
    "        while index < len(lines):\n",
    "            if len(lines[index]) < 10:\n",
    "                index = index + 1\n",
    "                continue\n",
    "            self.parse_time(lines[index])\n",
    "            index = index + 1\n",
    "        assert index == len(lines), 'Did not expect more data: {}'.format(lines[index])\n",
    "        return\n",
    "    \n",
    "    def parse_time(self, line):\n",
    "        data = line.split()\n",
    "        t = data[0]\n",
    "        tt = data[-1]\n",
    "        assert tt not in self.times, 'Duplicate time {}'.format(tt)\n",
    "        self.times[tt] = float(t)\n",
    "        return None\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerfLogData:\n",
    "    \"\"\"Store information about Polybench Data, with performance logs\"\"\"\n",
    "    \n",
    "    data_log_types = ('dram0', 'dram1', 'pmem1', 'pmem7')\n",
    "    \n",
    "    def __init__(self, data_dir='.', verbose=False):\n",
    "        # look for log files to parse further\n",
    "        self.verbose = verbose\n",
    "        self.data_dir = data_dir\n",
    "        self.data_frame = None\n",
    "        if self.verbose: print('PerfLogData: verbose enabled')\n",
    "        self.run_list = [log for log in os.listdir(data_dir) if 'run-comerge' in log and log.endswith('.log')]\n",
    "        if self.verbose: print('PerfLogData (init): run_list {}'.format(self.run_list))\n",
    "        self.results_dirs = []\n",
    "        for log in self.run_list:\n",
    "            with open(log, 'rt') as fd: self.results_dirs.append(fd.readline().strip().split()[1][2:])\n",
    "        if self.verbose: print('PerfLogData (init): results_dirs {}'.format(self.results_dirs))\n",
    "        self.run_data = {}\n",
    "        for resdir in self.results_dirs:\n",
    "            logs = [l for l in os.listdir('{}/{}'.format(data_dir, resdir))]\n",
    "            timestamp = resdir.split('-')[-1]\n",
    "            if timestamp not in self.run_data: self.run_data[timestamp] = {}\n",
    "            for l in logs:\n",
    "                datakey = self.get_data_key(l)\n",
    "                assert datakey not in self.run_data[timestamp], 'Unexpected duplicate data'\n",
    "                self.run_data[timestamp][datakey] = self.__load_log__('{}/{}/{}'.format(data_dir, resdir, l))\n",
    "        pass\n",
    "    \n",
    "\n",
    "    def __load_log__(self, log_file_name):\n",
    "        with open(log_file_name, 'rt') as fd:\n",
    "            return [x.strip() for x in fd.readlines()]\n",
    "        \n",
    "    def parse_perf_data(self, perfdata):\n",
    "        return PerfData(perfdata)\n",
    "\n",
    "    def parse_single_test(self, lines):\n",
    "        # first line of a block is the test we ran - extract the name\n",
    "        index = 0\n",
    "        line = lines[index].strip().split('/')\n",
    "        assert line[-1:][0].endswith('_time') # if not, this script isn't going to work right\n",
    "        testname = line[-1:][0][:-5]\n",
    "        # next line is CPU binding\n",
    "        index = index + 1\n",
    "        assert 'binding' in lines[index] # if not, this script isn't going to work right\n",
    "        binding = lines[index].strip().split(' ')[-1:][0].split(',')\n",
    "        # next line is allocation information\n",
    "        index = index + 1\n",
    "        allocation = 0\n",
    "        if 'VMMALLOC' in lines[index]: # this is a PMEM run\n",
    "            # TODO: do we need to track what was done here? For now we skip\n",
    "            index = index + 1\n",
    "        while 'allocate' in lines[index]:\n",
    "            line = lines[index].strip().split(' ')[-1]\n",
    "            allocation = allocation + int(line)\n",
    "            index = index + 1\n",
    "        # between allocation and Performance, Polybench will report the run time\n",
    "        pb_run_time = None\n",
    "        while 'Performance' not in lines[index]:\n",
    "            if len(lines[index]) > 3: \n",
    "                assert pb_run_time is None, 'Already have a runtime {}'.format(pb_run_time)\n",
    "                pb_run_time = float(lines[index])\n",
    "            index = index + 1\n",
    "        # next thing we are looking for is Performance\n",
    "        assert pb_run_time is not None, 'Did not find a runtime'\n",
    "        performance_data = self.parse_perf_data(lines[index:])\n",
    "        return (testname, binding, allocation, pb_run_time, performance_data)\n",
    "\n",
    "        \n",
    "    def parse_mem_log(self, log_type, logdata):\n",
    "        assert log_type in self.data_log_types, 'Invalid log type {}, options are {}'.format(log_type, self.data_log_types)\n",
    "        line = 0\n",
    "        data = []\n",
    "        while line < len(logdata):\n",
    "            start = line\n",
    "            end = start\n",
    "            while 'finished' not in logdata[line]: line = line + 1\n",
    "            end = line\n",
    "            data.append(self.parse_single_test(logdata[start:end]))            \n",
    "            line = line + 1\n",
    "        return data\n",
    "    \n",
    "    def parse_dram0_log(self, log_data):\n",
    "        return self.parse_mem_log('dram0', log_data)\n",
    "    \n",
    "    def parse_dram1_log(self, log_data):\n",
    "        return self.parse_mem_log('dram1', log_data)\n",
    "    \n",
    "    def parse_pmem1_log(self, log_data):\n",
    "        return self.parse_mem_log('pmem1', log_data)\n",
    "\n",
    "    def parse_pmem7_log(self, log_data):\n",
    "        return self.parse_mem_log('pmem7', log_data)\n",
    "    \n",
    "    def parse_make_log(self, log_data):\n",
    "        return None\n",
    "       \n",
    "    @staticmethod\n",
    "    def get_data_key(logname):\n",
    "        \"\"\"Given a log file name, figure out what kind of memory was being used and return the correct key\"\"\"\n",
    "        if 'dram0' in logname: return 'dram0'\n",
    "        if 'dram1' in logname: return 'dram1'\n",
    "        if 'pmem1' in logname: return 'pmem1'\n",
    "        if 'pmem7' in logname: return 'pmem7'\n",
    "        if 'make' in logname: return 'make'\n",
    "        raise ValueException\n",
    "        \n",
    "    def get_dataframe(self):\n",
    "        if self.data_frame is None: self.data_frame = self.__build_dataframe__()\n",
    "        return self.data_frame\n",
    "\n",
    "    \n",
    "    def __build_dataframe__(self):\n",
    "        row_data = []\n",
    "        for run in pld.run_data:\n",
    "            for rdtype in pld.run_data[run]:\n",
    "                parse_func = getattr(pld, 'parse_{}_log'.format(rdtype), None)\n",
    "                if parse_func is None:\n",
    "                    print('Unknown log type {}'.format(rdtype))\n",
    "                    continue\n",
    "                parsed_data = parse_func(pld.run_data[run][rdtype])\n",
    "                if parsed_data is None: continue # skip the unparsed make logs       \n",
    "                for td in parsed_data:\n",
    "                    row = {}\n",
    "                    row['run'] = run\n",
    "                    row['type'] = rdtype\n",
    "                    row['test'] = td[0]\n",
    "                    row['polybench-time'] = td[3]\n",
    "                    row['alloc'] = td[2]\n",
    "                    for property in td[-1].stats:\n",
    "                        property_data = td[-1].stats[property][property]\n",
    "                        if 'task-clock' == property:\n",
    "                            # task-clock {'task-clock': (11266.7, 'msec', 1.0, 'CPUs utilized')}\n",
    "                            row['task-clock'] = property_data[0]\n",
    "                            row['cpus-utilized'] = property_data[2]\n",
    "                        elif 'context-switches' == property:\n",
    "                            # context-switches {'context-switches': (4, 0.355, 'M/sec')}\n",
    "                            row['context-switches'] = property_data[0]\n",
    "                            row['context-switches-M-per-sec'] = property_data[1]\n",
    "                        elif 'cpu-migrations' == property:\n",
    "                            # cpu-migrations {'cpu-migrations': (0, 0.0, 'K/sec')}\n",
    "                            row['cpu-migrations'] = property_data[0]\n",
    "                            row['cpu-migrations-K-per-sec'] = property_data[1]\n",
    "                        elif 'page-faults' == property:\n",
    "                            # page-faults {'page-faults': (22030, 1955.441, 'M/sec')}\n",
    "                            row['page-faults'] = property_data[0]\n",
    "                            row['page-faults-M-per-sec'] = property_data[1]\n",
    "                        elif 'cycles' == property:\n",
    "                            # cycles {'cycles': (41292991932, 3665275.336, 'GHz', 30.75)}\n",
    "                            row['cycles'] = property_data[0]\n",
    "                            row['frequency (GHz)'] = property_data[1]\n",
    "                            assert property_data[2] == 'GHz', 'CPU frequency is not in GHz'\n",
    "                        elif 'instructions' == property:\n",
    "                            # instructions {'instructions': (57539842386, 1.39, 'insn per', 38.44)\n",
    "                            row['instructions'] = property_data[0]\n",
    "                            row['instructions-per-cycle'] = property_data[1]\n",
    "                        elif 'branches' == property:\n",
    "                            # branches {'branches': (6774876761, 601356005.77, 'M/sec', 38.45)}\n",
    "                            row['branches'] = property_data[0]\n",
    "                            row['branches-M-per-sec'] = property_data[1]\n",
    "                        elif 'branch-misses' == property:\n",
    "                            # branch-misses {'branch-misses': (4832518, 'of all branches', 38.46)}\n",
    "                            row['branch-misses'] = property_data[0]\n",
    "                        elif 'L1-dcache-loads' == property:\n",
    "                            # L1-dcache-loads {'L1-dcache-loads': (13526507060, 1200648594.0, 'M/sec', 38.47)}\n",
    "                            row['L1-dcache-loads'] = property_data[0]\n",
    "                            row['L1-dcache-loads-M-per-sec'] = property_data[1]\n",
    "                        elif 'L1-dcache-load-misses' == property:\n",
    "                            # L1-dcache-load-misses {'L1-dcache-load-misses': (9012615601, 'of all L1-dcache hits', 38.47)}\n",
    "                            row[property] = property_data[0]\n",
    "                        elif 'LLC-loads' == property:\n",
    "                            # LLC-loads {'LLC-loads': (849715461, 75422994.941, 'M/sec', 30.78)}\n",
    "                            row[property] = property_data[0]\n",
    "                            row['LLC-loads-M-per-sec'] = property_data[1]\n",
    "                        elif 'LLC-load-misses' == property:\n",
    "                            # LLC-load-misses {'LLC-load-misses': (4911229, 'of all LL-cache hits', 30.78)}\n",
    "                            row[property] = property_data[0]\n",
    "                        elif 'L1-icache-load-misses' == property:\n",
    "                            # L1-icache-load-misses {'L1-icache-load-misses': (3776205, 30.78)}\n",
    "                            row[property] = property_data[0]\n",
    "                        elif 'dTLB-loads' == property:\n",
    "                            # dTLB-loads {'dTLB-loads': (13547867184, 1202544575.182, 'M/sec', 30.78)}\n",
    "                            row[property] = property_data[0]\n",
    "                            row['dTLB-loads-M-per-sec'] = property_data[1]\n",
    "                        elif 'dTLB-load-misses' == property:\n",
    "                            # dTLB-load-misses {'dTLB-load-misses': (2066428912, 15.25, 'of all dTLB cache hits', 30.77)}\n",
    "                            row[property] = property_data[0]\n",
    "                            row['dTLB-load-misses-of-all-dTLB-cache-hits'] = property_data[1]\n",
    "                        elif 'iTLB-loads' == property:\n",
    "                            # iTLB-loads {'iTLB-loads': (338, 30.002, 'M/sec', 30.76)}\n",
    "                            row[property] = property_data[0]\n",
    "                            row['iTLB-loads-M-per-sec'] = property_data[1]\n",
    "                        elif 'iTLB-load-misses' == property:\n",
    "                            # iTLB-load-misses {'iTLB-load-misses': (5183, 1533.43, 'of all iTLB cache hits', 30.75)}\n",
    "                            row[property] = property_data[0]\n",
    "                            row['iTLB-load-misses-of-all-iTLB-cache-hits'] = property_data[1]\n",
    "                        else:\n",
    "                            assert False, 'Unknown property type {}'.format(property)\n",
    "                    row_data.append(row)\n",
    "        labels = [label for label in row_data[0]]\n",
    "        # validate my labels\n",
    "        for row in row_data:\n",
    "            test_labels = [label for label in row]\n",
    "            assert test_labels == labels, 'mismatched labels {} - {}'.format(labels, test_labels)\n",
    "        # build a flat row\n",
    "        flat_data = []\n",
    "        for row in row_data:\n",
    "            flat_data.append([row[label] for label in labels])\n",
    "        return pd.DataFrame(flat_data, columns = labels)\n",
    "    \n",
    "    def __build_average_dataframe__(self):\n",
    "        df = self.get_dataframe()\n",
    "        labels = []\n",
    "        # we drop the timestamp\n",
    "        for column in df.columns[1:3]: # type and test\n",
    "            labels.append(column)\n",
    "        for column in df.columns[3:]: # numeric values\n",
    "            if 'alloc' == column:\n",
    "                labels.append('alloc')\n",
    "                continue\n",
    "            labels.append('{} arithmetic mean'.format(column))\n",
    "            labels.append('{} harmonic mean'.format(column))\n",
    "            labels.append('{} geometric mean'.format(column))\n",
    "            labels.append('{} standard deviation'.format(column))\n",
    "        average_data = []\n",
    "        for type in df.type.unique():\n",
    "            for test in df.test.unique():\n",
    "                row = []\n",
    "                row.append(type)\n",
    "                row.append(test)\n",
    "                seldata = select_data(df, type, test)\n",
    "                for column in df.columns[3:]:\n",
    "                    if 'alloc' == column:\n",
    "                        row.append(statistics.mean(seldata[column]))\n",
    "                        continue\n",
    "                    test_mean = statistics.mean(seldata[column])\n",
    "                    if test_mean > 0.0:\n",
    "                        test_hmean = statistics.harmonic_mean(seldata[column])\n",
    "                        test_gmean = gmean(seldata[column])\n",
    "                        test_stdev = statistics.stdev(seldata[column], test_mean)\n",
    "                    else:\n",
    "                        test_hmean = 0.0\n",
    "                        test_gmean = 0.0\n",
    "                        test_stdev = 0.0\n",
    "                    row.append(test_mean)\n",
    "                    row.append(test_hmean)\n",
    "                    row.append(test_gmean)\n",
    "                    row.append(test_stdev)\n",
    "                average_data.append(row)\n",
    "        return pd.DataFrame(average_data, columns = labels)\n",
    "    \n",
    "    def get_average_dataframe(self):\n",
    "        if getattr(self, 'average_df', None) is None: \n",
    "            self.average_df = self.__build_average_dataframe__()\n",
    "        return self.average_df\n",
    "\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now I need to convert these to useful dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "test\n",
      "polybench-time arithmetic mean\n",
      "polybench-time harmonic mean\n",
      "polybench-time geometric mean\n",
      "polybench-time standard deviation\n",
      "alloc\n",
      "task-clock arithmetic mean\n",
      "task-clock harmonic mean\n",
      "task-clock geometric mean\n",
      "task-clock standard deviation\n",
      "cpus-utilized arithmetic mean\n",
      "cpus-utilized harmonic mean\n",
      "cpus-utilized geometric mean\n",
      "cpus-utilized standard deviation\n",
      "context-switches arithmetic mean\n",
      "context-switches harmonic mean\n",
      "context-switches geometric mean\n",
      "context-switches standard deviation\n",
      "context-switches-M-per-sec arithmetic mean\n",
      "context-switches-M-per-sec harmonic mean\n",
      "context-switches-M-per-sec geometric mean\n",
      "context-switches-M-per-sec standard deviation\n",
      "cpu-migrations arithmetic mean\n",
      "cpu-migrations harmonic mean\n",
      "cpu-migrations geometric mean\n",
      "cpu-migrations standard deviation\n",
      "cpu-migrations-K-per-sec arithmetic mean\n",
      "cpu-migrations-K-per-sec harmonic mean\n",
      "cpu-migrations-K-per-sec geometric mean\n",
      "cpu-migrations-K-per-sec standard deviation\n",
      "page-faults arithmetic mean\n",
      "page-faults harmonic mean\n",
      "page-faults geometric mean\n",
      "page-faults standard deviation\n",
      "page-faults-M-per-sec arithmetic mean\n",
      "page-faults-M-per-sec harmonic mean\n",
      "page-faults-M-per-sec geometric mean\n",
      "page-faults-M-per-sec standard deviation\n",
      "cycles arithmetic mean\n",
      "cycles harmonic mean\n",
      "cycles geometric mean\n",
      "cycles standard deviation\n",
      "frequency (GHz) arithmetic mean\n",
      "frequency (GHz) harmonic mean\n",
      "frequency (GHz) geometric mean\n",
      "frequency (GHz) standard deviation\n",
      "instructions arithmetic mean\n",
      "instructions harmonic mean\n",
      "instructions geometric mean\n",
      "instructions standard deviation\n",
      "instructions-per-cycle arithmetic mean\n",
      "instructions-per-cycle harmonic mean\n",
      "instructions-per-cycle geometric mean\n",
      "instructions-per-cycle standard deviation\n",
      "branches arithmetic mean\n",
      "branches harmonic mean\n",
      "branches geometric mean\n",
      "branches standard deviation\n",
      "branches-M-per-sec arithmetic mean\n",
      "branches-M-per-sec harmonic mean\n",
      "branches-M-per-sec geometric mean\n",
      "branches-M-per-sec standard deviation\n",
      "branch-misses arithmetic mean\n",
      "branch-misses harmonic mean\n",
      "branch-misses geometric mean\n",
      "branch-misses standard deviation\n",
      "L1-dcache-loads arithmetic mean\n",
      "L1-dcache-loads harmonic mean\n",
      "L1-dcache-loads geometric mean\n",
      "L1-dcache-loads standard deviation\n",
      "L1-dcache-loads-M-per-sec arithmetic mean\n",
      "L1-dcache-loads-M-per-sec harmonic mean\n",
      "L1-dcache-loads-M-per-sec geometric mean\n",
      "L1-dcache-loads-M-per-sec standard deviation\n",
      "L1-dcache-load-misses arithmetic mean\n",
      "L1-dcache-load-misses harmonic mean\n",
      "L1-dcache-load-misses geometric mean\n",
      "L1-dcache-load-misses standard deviation\n",
      "LLC-loads arithmetic mean\n",
      "LLC-loads harmonic mean\n",
      "LLC-loads geometric mean\n",
      "LLC-loads standard deviation\n",
      "LLC-loads-M-per-sec arithmetic mean\n",
      "LLC-loads-M-per-sec harmonic mean\n",
      "LLC-loads-M-per-sec geometric mean\n",
      "LLC-loads-M-per-sec standard deviation\n",
      "LLC-load-misses arithmetic mean\n",
      "LLC-load-misses harmonic mean\n",
      "LLC-load-misses geometric mean\n",
      "LLC-load-misses standard deviation\n",
      "L1-icache-load-misses arithmetic mean\n",
      "L1-icache-load-misses harmonic mean\n",
      "L1-icache-load-misses geometric mean\n",
      "L1-icache-load-misses standard deviation\n",
      "dTLB-loads arithmetic mean\n",
      "dTLB-loads harmonic mean\n",
      "dTLB-loads geometric mean\n",
      "dTLB-loads standard deviation\n",
      "dTLB-loads-M-per-sec arithmetic mean\n",
      "dTLB-loads-M-per-sec harmonic mean\n",
      "dTLB-loads-M-per-sec geometric mean\n",
      "dTLB-loads-M-per-sec standard deviation\n",
      "dTLB-load-misses arithmetic mean\n",
      "dTLB-load-misses harmonic mean\n",
      "dTLB-load-misses geometric mean\n",
      "dTLB-load-misses standard deviation\n",
      "dTLB-load-misses-of-all-dTLB-cache-hits arithmetic mean\n",
      "dTLB-load-misses-of-all-dTLB-cache-hits harmonic mean\n",
      "dTLB-load-misses-of-all-dTLB-cache-hits geometric mean\n",
      "dTLB-load-misses-of-all-dTLB-cache-hits standard deviation\n",
      "iTLB-loads arithmetic mean\n",
      "iTLB-loads harmonic mean\n",
      "iTLB-loads geometric mean\n",
      "iTLB-loads standard deviation\n",
      "iTLB-loads-M-per-sec arithmetic mean\n",
      "iTLB-loads-M-per-sec harmonic mean\n",
      "iTLB-loads-M-per-sec geometric mean\n",
      "iTLB-loads-M-per-sec standard deviation\n",
      "iTLB-load-misses arithmetic mean\n",
      "iTLB-load-misses harmonic mean\n",
      "iTLB-load-misses geometric mean\n",
      "iTLB-load-misses standard deviation\n",
      "iTLB-load-misses-of-all-iTLB-cache-hits arithmetic mean\n",
      "iTLB-load-misses-of-all-iTLB-cache-hits harmonic mean\n",
      "iTLB-load-misses-of-all-iTLB-cache-hits geometric mean\n",
      "iTLB-load-misses-of-all-iTLB-cache-hits standard deviation\n"
     ]
    }
   ],
   "source": [
    "pld = PerfLogData()\n",
    "adf = pld.get_average_dataframe()\n",
    "df = pld.get_dataframe()\n",
    "for col in adf.columns: print(col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2mm' '3mm' 'atax' 'bicg' 'cholesky' 'doitgen' 'gemm' 'gemver' 'gesummv'\n",
      " 'mvt' 'symm' 'syr2k' 'syrk' 'trisolv' 'trmm' 'durbin' 'dynprog'\n",
      " 'gramschmidt' 'lu' 'ludcmp' 'correlation' 'covariance' 'floyd-warshall'\n",
      " 'reg_detect' 'adi' 'fdtd-2d' 'fdtd-apml' 'jacobi-1d-imper'\n",
      " 'jacobi-2d-imper' 'seidel-2d'] 30\n",
      "['dram0' 'dram1' 'pmem1' 'pmem7'] 4\n"
     ]
    }
   ],
   "source": [
    "def select_data(df, Dataset='EXTRALARGE_DATASET', Type='dram', Test='2mm'):\n",
    "    return df.loc[(df['Dataset'] == Dataset) & (df['Type'] == Type) & (df['Test'] == Test)]\n",
    "\n",
    "def select_data(df, type, test):\n",
    "    return df.loc[(df['type'] == type) & (df['test'] == test)]\n",
    "\n",
    "#print(select_data(df, 'dram0', '2mm'))\n",
    "print(df.test.unique(), len(df.test.unique()))\n",
    "print(df.type.unique(), len(df.type.unique()))\n",
    "     \n",
    "average_df = get_average_dataframe(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test             Memory   Task Clock  PB Time       Instructions  LLC Load Misses    IPC  DTLB-LM  Page Faults\n",
      "2mm              dram0      11667.14    11.63     57545426065.20       6334574.60   1.35    16.07  1889.26\n",
      "2mm              dram1      11486.71    11.45     57524149814.80       6475998.20   1.36    15.54  1918.87\n",
      "2mm              pmem1      23542.77    21.01     59597380843.80         69420.60   0.69    16.62   947.60\n",
      "2mm              pmem7      17329.73    15.94     59563873474.60        136920.40   0.94    15.59  1287.49\n",
      "3mm              dram0      17731.50    17.69     81207578951.60      11048485.80   1.25    16.42  1739.62\n",
      "3mm              dram1      17340.93    17.30     81214361307.60       8911634.60   1.27    15.99  1777.81\n",
      "3mm              pmem1      33748.41    31.21     83322856720.80         95886.80   0.67    15.66   921.53\n",
      "3mm              pmem7      24158.93    22.77     83270758268.80        246186.00   0.94    16.07  1287.32\n",
      "atax             dram0       1221.30     0.39      4847882759.00        306571.20   1.09     0.00 360125.36\n",
      "atax             dram1       1236.28     0.40      4828841444.00        375959.20   1.06     0.00 355757.69\n",
      "atax             pmem1       6318.00     0.67      7627905039.80         95376.60   0.33     0.00 69627.31\n",
      "atax             pmem7       3165.76     0.66      7660187458.00         83686.80   0.66     0.00 138986.19\n",
      "bicg             dram0       1066.57     0.44      3610886409.80        246661.40   0.93     0.00 309803.84\n",
      "bicg             dram1       1069.14     0.44      3614432850.60        294270.00   0.92     0.01 309045.67\n",
      "bicg             pmem1       5387.78     0.54      6227190936.60         81963.80   0.31     0.00 61351.19\n",
      "bicg             pmem7       2755.05     0.54      6252020655.40         70502.80   0.62     0.00 119992.17\n",
      "cholesky         dram0      12313.16    12.26     48296530391.40       1627452.20   1.07     0.09  2544.15\n",
      "cholesky         dram1      12313.27    12.26     48295864465.80       1609079.80   1.07     0.09  2544.24\n",
      "cholesky         pmem1      20380.30    17.75     50361101605.20        227336.40   0.68     0.08  1550.56\n",
      "cholesky         pmem7      17203.92    15.78     50343644312.20        275205.20   0.80     0.08  1837.00\n",
      "doitgen          dram0      13972.59    13.85     69628893347.60        138388.60   1.36     0.00  9394.69\n",
      "doitgen          dram1      13962.39    13.84     69633651598.00        198157.20   1.36     0.00  9401.69\n",
      "doitgen          pmem1      16829.37    13.93     71830617927.00         60667.00   1.16     0.00  7816.21\n",
      "doitgen          pmem7      15430.48    13.91     71846977918.40        116273.00   1.27     0.00  8524.47\n",
      "gemm             dram0      30702.72    30.66     72246508152.60     109386506.80   0.64    43.03   765.33\n",
      "gemm             dram1      30696.36    30.65     72240015390.80     108413860.80   0.64    43.02   765.43\n",
      "gemm             pmem1      37307.59    34.73     74270233891.40         64549.00   0.54    42.76   637.26\n",
      "gemm             pmem7      38205.97    36.80     74292248736.80        264687.60   0.53    42.67   622.17\n",
      "gemver           dram0       4450.87     3.62      7307218851.20      49712702.40   0.45    13.81 98808.91\n",
      "gemver           dram1       4483.38     3.65      7327518099.40      49804492.80   0.44    13.80 98088.39\n",
      "gemver           pmem1      13720.30     8.06     10115131606.80        119033.80   0.20    11.60 32072.59\n",
      "gemver           pmem7       7756.97     5.25     10150037320.60        144203.00   0.36    11.64 56733.43\n",
      "gesummv          dram0        971.45     0.26      2827466766.40        347843.40   0.79     0.00 402536.58\n",
      "gesummv          dram1        968.42     0.26      2829208666.80        395027.40   0.80     0.01 403750.91\n",
      "gesummv          pmem1       5636.18     0.41      5531352101.00         94803.80   0.27     0.00 69384.61\n",
      "gesummv          pmem7       2855.92     0.38      5557214474.60         84906.40   0.53     0.00 136946.84\n",
      "mvt              dram0       4389.96     3.56      5649279289.00      41657986.40   0.35    17.33 100156.38\n",
      "mvt              dram1       4410.08     3.58      5637280358.00      42013489.60   0.35    17.36 99697.66\n",
      "mvt              pmem1      10537.24     4.89      8413675800.80        116185.00   0.22    14.10 41750.77\n",
      "mvt              pmem7       7053.83     4.54      8461856923.80        136163.20   0.33    14.10 62371.62\n",
      "symm             dram0      52610.10    52.56     40490353921.00     125562279.80   0.21    62.05   446.60\n",
      "symm             dram1      52443.26    52.40     40415676689.80     121194002.40   0.21    61.92   448.03\n",
      "symm             pmem1      72627.94    70.05     42580133104.20        162083.60   0.16    61.43   327.33\n",
      "symm             pmem7      62336.27    60.93     42533466664.80        378305.40   0.19    61.36   381.36\n",
      "syr2k            dram0      18852.41    18.81    104167059313.60       1046978.00   1.51     0.00  1246.29\n",
      "syr2k            dram1      18783.71    18.74    104173207896.60       1168929.60   1.51     0.00  1250.86\n",
      "syr2k            pmem1      29808.00    27.24    106207396416.00        176668.40   0.97     0.00   797.52\n",
      "syr2k            pmem7      26660.68    25.25    106191926367.60        352169.40   1.08     0.00   891.70\n",
      "syrk             dram0       9234.70     9.20     64125000062.60        351717.40   1.89     0.00  1698.18\n",
      "syrk             dram1       9244.20     9.21     64116857193.80        380859.60   1.89     0.00  1696.61\n",
      "syrk             pmem1      19193.50    16.68     66157448844.00        125757.00   0.94     0.00   831.42\n",
      "syrk             pmem7      15011.55    13.63     66191522631.80        174096.80   1.20     0.00  1063.10\n",
      "trisolv          dram0        981.80     0.15      3044239634.80        307571.40   0.85     0.01 448022.26\n",
      "trisolv          dram1        988.66     0.16      3020777814.00        355522.00   0.83     0.01 444840.91\n",
      "trisolv          pmem1       5948.26     0.30      5825416678.20         87871.20   0.27     0.00 73951.41\n",
      "trisolv          pmem7       2800.61     0.30      5837657637.00         81964.00   0.57     0.00 157082.92\n",
      "trmm             dram0      44298.26    44.18    256416449844.00      21871624.80   1.58     0.03  1412.24\n",
      "trmm             dram1      45610.86    45.49    256404394369.20      22068777.40   1.53     0.03  1371.60\n",
      "trmm             pmem1      82420.26    79.57    258616437475.00       1693408.00   0.86     0.03   762.39\n",
      "trmm             pmem7      76472.12    74.95    258611373008.80       2390058.00   0.92     0.03   821.71\n",
      "durbin           dram0       2467.11     1.75      2562248659.80       2446421.20   0.28    16.08 158418.62\n",
      "durbin           dram1       2525.33     1.79      2568582849.00       2412870.20   0.28    16.18 154774.85\n",
      "durbin           pmem1       9355.53     4.12      5263204132.00        121935.40   0.15    11.57 41800.59\n",
      "durbin           pmem7       5076.61     2.60      5317495016.60        121194.20   0.28    11.59 77033.39\n",
      "dynprog          dram0      11991.54    11.98     76157372959.60      24698790.80   1.73     0.01  2660.77\n",
      "dynprog          dram1      12004.62    12.00     76125045224.00      24618490.40   1.73     0.01  2658.03\n",
      "dynprog          pmem1      69041.18    66.63     78402190024.40        480332.20   0.31     0.01   464.85\n",
      "dynprog          pmem7      31985.76    30.64     78238442374.00        707154.00   0.67     0.01  1003.35\n",
      "gramschmidt      dram0      71890.02    71.84     52441945001.80     110779312.20   0.20    91.33   326.96\n",
      "gramschmidt      dram1      71702.63    71.66     52427993748.80     119976560.00   0.20    91.26   327.85\n",
      "gramschmidt      pmem1      81374.28    78.80     54446324114.20         65934.00   0.18    90.24   292.23\n",
      "gramschmidt      pmem7      74359.02    72.95     54495133051.20        454017.40   0.20    90.32   319.81\n",
      "lu               dram0      16976.89    16.91     85816742093.80     467607534.80   1.38     0.03  1844.19\n",
      "lu               dram1      17306.71    17.24     85620715868.60     448435556.20   1.34     0.03  1809.08\n",
      "lu               pmem1     220827.21   218.19     88629661486.40        385609.60   0.11     0.03   143.02\n",
      "lu               pmem7      55163.25    53.74     87884740726.60        701081.00   0.43     0.03   572.54\n",
      "ludcmp           dram0     928050.57   927.81    943941967686.00    9129810383.00   0.28    51.36   134.85\n",
      "ludcmp           dram1     939132.63   938.89    944053559085.40    9029768401.20   0.27    51.37   133.34\n",
      "ludcmp           pmem1    1321129.29  1317.80    947621979028.20      18925150.60   0.20    51.31    94.93\n",
      "ludcmp           pmem7    1238383.96  1236.71    947394780809.60      31445808.20   0.21    51.39   101.29\n",
      "correlation      dram0     109180.60   109.14     95266493151.80     555053400.60   0.24    90.94   322.75\n",
      "correlation      dram1     109291.98   109.25     95234727210.80     544243692.00   0.24    90.92   322.42\n",
      "correlation      pmem1     126387.15   123.85     97296295363.20        694270.40   0.21    90.17   281.00\n",
      "correlation      pmem7     121246.84   119.86     97286483686.20       1626227.80   0.22    90.22   292.90\n",
      "covariance       dram0      20596.25    20.58     20588089334.20       5656969.80   0.27    84.15   617.44\n",
      "covariance       dram1      20550.41    20.54     20628633765.80       5182546.40   0.27    84.12   618.80\n",
      "covariance       pmem1      24639.85    22.19     22620360673.40        113675.80   0.25    81.59   527.38\n",
      "covariance       pmem7      22306.97    20.95     22611955064.60        190862.00   0.28    81.65   582.57\n",
      "floyd-warshall   dram0      67086.46    67.02    448551656822.60      47532066.20   1.82     0.01   466.68\n",
      "floyd-warshall   dram1      68754.05    68.69    448537826234.40      45799430.60   1.78     0.01   455.37\n",
      "floyd-warshall   pmem1     163503.82   160.87    450914806229.00       1689446.20   0.75     0.01   193.17\n",
      "floyd-warshall   pmem7     157347.05   155.92    450834943405.80       2921899.80   0.78     0.01   200.74\n",
      "reg_detect       dram0      30006.89    30.00    151833486702.80      37402848.00   1.38     0.00  1653.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reg_detect       dram1      30503.58    30.50    151790930805.80      36812270.40   1.36     0.00  1626.13\n",
      "reg_detect       pmem1     333314.89   330.90    155098341454.60       1631421.20   0.13     0.00   149.65\n",
      "reg_detect       pmem7      93172.21    91.82    154086824825.80       2054305.80   0.45     0.00   535.37\n",
      "adi              dram0      46650.87    45.91    123685246969.60     155641516.20   0.72     0.07  8040.16\n",
      "adi              dram1      46904.53    46.16    123730369324.80     153085134.40   0.72     0.07  7996.71\n",
      "adi              pmem1     259819.49   254.77    127224344489.80       4141685.80   0.14     0.07  1444.61\n",
      "adi              pmem7     136203.29   133.80    126741156664.80       5334855.60   0.25     0.07  2755.78\n",
      "fdtd-2d          dram0      33575.67    32.83    110796133537.40     356753098.60   0.90     0.02 11171.20\n",
      "fdtd-2d          dram1      33988.83    33.25    110789547552.20     344924138.80   0.89     0.02 11035.41\n",
      "fdtd-2d          pmem1     278714.45   273.66    114401731300.40       2567509.00   0.11     0.01  1346.91\n",
      "fdtd-2d          pmem7     105363.79   102.96    113736179641.00       3499554.60   0.29     0.01  3562.37\n",
      "fdtd-apml        dram0        469.63     0.27      1952310923.60        212061.00   1.14     0.03 354179.61\n",
      "fdtd-apml        dram1        464.95     0.26      1928740910.00        189357.80   1.13     0.03 357648.96\n",
      "fdtd-apml        pmem1       3542.39     0.44      4200901795.80         55497.20   0.32     0.03 46974.79\n",
      "fdtd-apml        pmem7       1945.19     0.31      4233372945.80         53803.80   0.59     0.02 85572.91\n",
      "jacobi-1d-imper  dram0      27303.20    27.22     75273489259.60     388713790.80   0.75     0.01  1432.82\n",
      "jacobi-1d-imper  dram1      27687.91    27.61     75274572658.40     376869842.20   0.74     0.01  1412.91\n",
      "jacobi-1d-imper  pmem1     259196.46   256.51     78216809041.60       2140658.40   0.08     0.00   152.01\n",
      "jacobi-1d-imper  pmem7      95951.20    94.49     77538918990.80       2189724.20   0.22     0.00   410.62\n",
      "jacobi-2d-imper  dram0      19592.53    19.10     62178346709.20     251578200.60   0.86     0.01 12763.74\n",
      "jacobi-2d-imper  dram1      19894.30    19.41     62170636745.20     245769006.60   0.85     0.01 12570.19\n",
      "jacobi-2d-imper  pmem1     185773.41   181.57     65210578123.40       1207709.20   0.10     0.00  1347.53\n",
      "jacobi-2d-imper  pmem7      67506.41    65.45     64784530845.40       1549648.00   0.26     0.00  3708.47\n",
      "seidel-2d        dram0      26369.82    26.27     40320950493.80        151095.20   0.41     0.00  1853.90\n",
      "seidel-2d        dram1      26387.65    26.29     40343001540.20        273714.00   0.41     0.00  1852.64\n",
      "seidel-2d        pmem1      35124.80    32.36     42490921006.60         72298.40   0.33     0.00  1399.73\n",
      "seidel-2d        pmem7      27788.44    26.31     42397444856.60        196097.00   0.41     0.00  1769.18\n"
     ]
    }
   ],
   "source": [
    "print('Test             Memory   Task Clock  PB Time       Instructions  LLC Load Misses    IPC  DTLB-LM  Page Faults')\n",
    "for test in df.test.unique():\n",
    "    for dftype in df.type.unique():\n",
    "        seldata = select_data(average_df, dftype, test)\n",
    "        print('{:16} {:8} {:10.2f} {:8.2f} {:18.2f} {:16.2f} {:6.2f} {:8.2f} {:8.2f}'.format(test, dftype,\n",
    "                                    seldata['task-clock arithmetic mean'].values[0],\n",
    "                                    seldata['polybench-time arithmetic mean'].values[0],\n",
    "                                    seldata['instructions arithmetic mean'].values[0],\n",
    "                                    seldata['LLC-load-misses arithmetic mean'].values[0],\n",
    "                                    seldata['instructions-per-cycle arithmetic mean'].values[0],\n",
    "                                    seldata['dTLB-load-misses-of-all-dTLB-cache-hits arithmetic mean'].values[0],\n",
    "                                    seldata['page-faults-M-per-sec arithmetic mean'].values[0]\n",
    "                                                                                    ))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
